{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d7ff7fc",
   "metadata": {},
   "source": [
    "## 正常"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccca5a9",
   "metadata": {},
   "source": [
    "### 微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c68e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hcgf\n",
    "gl = hcgf.GlmLora(\"THUDM/chatglm-6b\", device=\"cuda:1\")\n",
    "gl.load_data(\"./data/chatgpt_finetune_faq.json\").tune()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925aa224",
   "metadata": {},
   "source": [
    "### 推理\n",
    "\n",
    "重启下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "579811ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer and model of THUDM/chatglm-6b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "/home/env/anaconda3/envs/tf29/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01613473892211914,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 27,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 8,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33818329a4e9436883d966b2ec50a333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing peft model\n",
      "trainable params: 3670016 || all params: 6258876416 \n",
      "trainable%: 0.05863697820615348\n"
     ]
    }
   ],
   "source": [
    "import hcgf\n",
    "gl = hcgf.GlmLora(\"THUDM/chatglm-6b\", load_in_8bit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3384c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "gl.load_pretrained(\"output/ckpt/lora-ckpt-88730.pt\").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "538ca979",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = \"问题：公司破产孕妇怎么赔偿？\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11ddbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.chat(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4400f7ef",
   "metadata": {},
   "source": [
    "## 8bit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd758105",
   "metadata": {},
   "source": [
    "### 微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d419955f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "CUDA SETUP: CUDA runtime path found: /home/env/anaconda3/envs/tf29/lib/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 7.0\n",
      "CUDA SETUP: Detected CUDA version 116\n",
      "CUDA SETUP: Loading binary /home/env/anaconda3/envs/tf29/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda116_nocublaslt.so...\n",
      "Loading tokenizer and model of THUDM/chatglm-6b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/env/anaconda3/envs/tf29/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: Compute capability < 7.5 detected! Only slow 8-bit matmul is supported for your GPU!\n",
      "  warn(msg)\n",
      "/home/env/anaconda3/envs/tf29/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015835285186767578,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 8,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80eeb92cffdd4f19a5c4e429485a1f7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing peft model\n",
      "trainable params: 3670016 || all params: 6258876416 \n",
      "trainable%: 0.05863697820615348\n"
     ]
    }
   ],
   "source": [
    "import hcgf\n",
    "gl = hcgf.GlmLora(\"THUDM/chatglm-6b\", load_in_8bit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420daa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gl.load_data(\"./data/chatgpt_finetune_faq.json\").tune()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c72d70",
   "metadata": {},
   "source": [
    "### 推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42163720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389316c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e9d024",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
